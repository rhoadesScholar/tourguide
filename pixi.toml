[project]
name = "ng-live"
version = "0.1.0"
description = "Live streaming and AI narration for Neuroglancer"
authors = ["Your Name <your.email@example.com>"]
channels = ["conda-forge"]
platforms = ["linux-64", "osx-64", "osx-arm64", "win-64"]

[dependencies]
python = "3.11.*"
fastapi = "*"
uvicorn = "*"
pillow = ">=12.0.0,<13"
websockets = "*"
pip = "*"
google-generativeai = ">=0.8.6,<0.9"
python-dotenv = "*"
ffmpeg = "*"

[pypi-dependencies]
neuroglancer = "*"
anthropic = "*"
ollama = "*"
edge-tts = "*"

[tasks]
install-chatterbox = { cmd = "pip install 'numpy>=1.24.0,<1.26.0' && pip install chatterbox-tts" }
start = { cmd = "pkill -9 -f 'python.*main.py' 2>/dev/null || true && python server/main.py" }
dev = { cmd = "pkill -9 -f 'python.*main.py' 2>/dev/null || true && python server/main.py --fps 3" }

[feature.narrator.pypi-dependencies]
# Stage 4: Add your AI/vision model SDK here
# anthropic = "*"
# openai = "*"

[feature.tts.pypi-dependencies]
# Stage 5: Add TTS library here
# pyttsx3 = "*"
